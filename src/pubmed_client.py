import requests
import xml.etree.ElementTree as ET
from typing import List, Dict, Optional
import time
import re
import os


class PubMedClient:
    def __init__(self, config: Dict, paths_config: Dict):
        self.base_url = config['pubmed']['base_url']
        self.email = config['pubmed']['email']
        self.tool = config['pubmed']['tool']
        self.max_results = config['pubmed']['max_results']
        self.rate_limit = config['pubmed']['rate_limit']
        self.paths_config = paths_config

    def search_drug_articles(self, drug_name: str, max_results: int = None) -> List[Dict]:
        """
        ä¼˜åŒ–çš„è¯ç‰©æ–‡çŒ®æœç´¢æµç¨‹ - ä¼˜å…ˆæœç´¢æ˜ç¡®é¶ç‚¹çš„æ–‡ç« 
        """
        if max_results is None:
            max_results = self.max_results

        print(f"ğŸ” æœç´¢è¯ç‰© '{drug_name}' çš„é¶ç‚¹ç›¸å…³æ–‡çŒ®...")
        start_time = time.time()

        # ä½¿ç”¨ä¼˜åŒ–çš„æœç´¢ç­–ç•¥ï¼Œä¼˜å…ˆé¶ç‚¹æ˜ç¡®çš„ç»“æœ
        article_ids = self._search_target_specific_articles(drug_name, max_results)

        if not article_ids:
            print(f"âŒ æœªæ‰¾åˆ°è¯ç‰© '{drug_name}' çš„ç›¸å…³æ–‡çŒ®")
            return []

        print(f"ğŸ“„ è·å– {len(article_ids)} ç¯‡æ–‡çŒ®çš„è¯¦ç»†ä¿¡æ¯...")
        articles = self.get_article_details(article_ids)

        elapsed_time = time.time() - start_time
        print(f"âœ… æˆåŠŸè·å– {len(articles)} ç¯‡æ–‡çŒ®ï¼Œè€—æ—¶ {elapsed_time:.1f} ç§’")

        return articles

    def _search_target_specific_articles(self, drug_name: str, max_results: int) -> List[str]:
        """
        ä¼˜å…ˆæœç´¢æ˜ç¡®è¯´æ˜é¶ç‚¹çš„æ–‡ç«  - ä¼˜åŒ–é€Ÿåº¦ç‰ˆæœ¬
        """
        # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘æœç´¢è¯æ•°é‡ï¼Œåªä¿ç•™æœ€æœ‰æ•ˆçš„
        search_terms = [
            # æœ€æ˜ç¡®çš„é¶ç‚¹æœç´¢
            f'{drug_name}[Title/Abstract] AND (target OR targets OR targeting)',
            f'{drug_name}[Title/Abstract] AND (binds to OR binding to OR binds)',
            f'{drug_name}[Title/Abstract] AND (inhibits OR inhibitor of OR inhibition)',

            # å¤‡ç”¨æœç´¢
            f'{drug_name}[Title/Abstract] AND (mechanism of action OR MOA)',
            f'{drug_name}[Title/Abstract]'
        ]

        all_article_ids = []

        print(f"   ğŸ¯ ä½¿ç”¨ {len(search_terms)} ä¸ªä¼˜åŒ–æœç´¢è¯...")

        for i, search_term in enumerate(search_terms, 1):
            if len(all_article_ids) >= max_results:
                break

            try:
                params = {
                    'db': 'pubmed',
                    'term': search_term,
                    'retmode': 'json',
                    'retmax': min(8, max_results - len(all_article_ids)),  # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘æ¯æ¬¡è¯·æ±‚æ•°é‡
                    'sort': 'relevance',
                    'email': self.email,
                    'tool': self.tool
                }

                # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘è¶…æ—¶æ—¶é—´
                response = requests.get(f"{self.base_url}/esearch.fcgi", params=params, timeout=15)
                response.raise_for_status()
                data = response.json()
                batch_ids = data.get('esearchresult', {}).get('idlist', [])

                if batch_ids:
                    # æ·»åŠ æ–°IDï¼Œé¿å…é‡å¤
                    new_ids = [id for id in batch_ids if id not in all_article_ids]
                    all_article_ids.extend(new_ids)
                    print(f"     âœ… æœç´¢è¯ {i}: æ‰¾åˆ° {len(new_ids)} ç¯‡æ–°æ–‡çŒ®")
                else:
                    print(f"     âš ï¸  æœç´¢è¯ {i}: æ— ç»“æœ")

            except Exception as e:
                print(f"     âŒ æœç´¢è¯ {i}: å¤±è´¥ - {str(e)[:50]}")

            # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘è¯·æ±‚é—´å»¶è¿Ÿ
            if i < len(search_terms):
                time.sleep(0.3)  # ä»0.5ç§’å‡å°‘åˆ°0.3ç§’

        # è¿”å›å»é‡åçš„ç»“æœï¼Œé™åˆ¶æ•°é‡
        unique_ids = list(set(all_article_ids))[:max_results]
        print(f"   ğŸ“Š æ€»è®¡æ‰¾åˆ° {len(unique_ids)} ç¯‡å”¯ä¸€æ–‡çŒ®")

        return unique_ids

    def get_article_details(self, article_ids: List[str]) -> List[Dict]:
        """
        è·å–æ–‡ç« è¯¦ç»†ä¿¡æ¯
        """
        if not article_ids:
            return []

        # é™åˆ¶æ¯æ¬¡è·å–çš„æ•°é‡
        batch_ids = article_ids[:self.max_results]

        params = {
            'db': 'pubmed',
            'id': ','.join(batch_ids),
            'retmode': 'xml'
        }

        try:
            response = requests.get(f"{self.base_url}/efetch.fcgi", params=params, timeout=30)
            response.raise_for_status()

            articles = self._parse_articles_xml(response.content)
            print(f"   âœ… æˆåŠŸè§£æ {len(articles)} ç¯‡æ–‡çŒ®")
            return articles

        except Exception as e:
            print(f"   âŒ è·å–æ–‡ç« è¯¦æƒ…é”™è¯¯: {e}")
            return []

    def _parse_articles_xml(self, xml_content: str) -> List[Dict]:
        """
        è§£æPubMed XML
        """
        try:
            root = ET.fromstring(xml_content)
            articles = []

            for article in root.findall('.//PubmedArticle'):
                article_info = self._parse_single_article(article)
                if article_info:
                    articles.append(article_info)

            return articles

        except Exception as e:
            print(f"   âŒ è§£ææ–‡ç« XMLé”™è¯¯: {e}")
            return []

    def _parse_single_article(self, article_element) -> Optional[Dict]:
        """
        è§£æå•ç¯‡æ–‡ç« 
        """
        try:
            # æå–æ ‡é¢˜
            title_element = article_element.find('.//ArticleTitle')
            title = title_element.text if title_element is not None else "No title"

            if not title or title == "No title":
                return None

            # æå–æ‘˜è¦
            abstract_texts = []
            for abstract_element in article_element.findall('.//AbstractText'):
                if abstract_element.text:
                    text = abstract_element.text.strip()
                    if text and text not in abstract_texts:
                        abstract_texts.append(text)

            abstract = " ".join(abstract_texts) if abstract_texts else "No abstract available"

            # æå–å¹´ä»½
            year = self._extract_year(article_element)

            # æå–PubMed ID
            pmid_element = article_element.find('.//PMID')
            pmid = pmid_element.text if pmid_element is not None else "Unknown"

            return {
                'pubmed_id': pmid,
                'title': title,
                'abstract': abstract,
                'year': year
            }

        except Exception as e:
            print(f"   âŒ è§£æå•ç¯‡æ–‡ç« XMLé”™è¯¯: {e}")
            return None

    def _extract_year(self, article_element) -> str:
        """
        æå–å¹´ä»½
        """
        pub_date_element = article_element.find('.//PubDate/Year')
        if pub_date_element is not None and pub_date_element.text:
            return pub_date_element.text

        medline_date = article_element.find('.//PubDate/MedlineDate')
        if medline_date is not None and medline_date.text:
            year_match = re.search(r'(\d{4})', medline_date.text)
            if year_match:
                return year_match.group(1)

        return "Unknown"